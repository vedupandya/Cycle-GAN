{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms, datasets\n",
        "import pytorch_lightning as pl\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "\n",
        "# Generator Model\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_nc, output_nc, n_residual_blocks=9):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        model = [\n",
        "            nn.Conv2d(input_nc, 64, kernel_size=7, stride=1, padding=3, bias=False),\n",
        "            nn.InstanceNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "        ]\n",
        "\n",
        "        in_channels = 64\n",
        "        out_channels = in_channels * 2\n",
        "        for _ in range(2):\n",
        "            model += [\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1, bias=False),\n",
        "                nn.InstanceNorm2d(out_channels),\n",
        "                nn.ReLU(inplace=True),\n",
        "            ]\n",
        "            in_channels = out_channels\n",
        "            out_channels = in_channels * 2\n",
        "\n",
        "        for _ in range(n_residual_blocks):\n",
        "            model += [ResidualBlock(in_channels)]\n",
        "\n",
        "        out_channels = in_channels // 2\n",
        "        for _ in range(2):\n",
        "            model += [\n",
        "                nn.ConvTranspose2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1, output_padding=1, bias=False),\n",
        "                nn.InstanceNorm2d(out_channels),\n",
        "                nn.ReLU(inplace=True),\n",
        "            ]\n",
        "            in_channels = out_channels\n",
        "            out_channels = in_channels // 2\n",
        "\n",
        "        model += [nn.Conv2d(64, output_nc, kernel_size=7, stride=1, padding=3), nn.Tanh()]\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "# Residual Block for Generator\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.InstanceNorm2d(channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.InstanceNorm2d(channels),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.block(x)\n",
        "\n",
        "\n",
        "# Discriminator Model\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_nc):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        model = [\n",
        "            nn.Conv2d(input_nc, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        ]\n",
        "\n",
        "        in_channels = 64\n",
        "        out_channels = in_channels * 2\n",
        "        for _ in range(3):\n",
        "            model += [\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "                nn.InstanceNorm2d(out_channels),\n",
        "                nn.LeakyReLU(0.2, inplace=True),\n",
        "            ]\n",
        "            in_channels = out_channels\n",
        "            out_channels = in_channels * 2\n",
        "\n",
        "        model += [\n",
        "            nn.Conv2d(in_channels, 1, kernel_size=4, padding=1)\n",
        "        ]\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "# CycleGAN Model in PyTorch Lightning\n",
        "class CycleGAN(pl.LightningModule):\n",
        "    def __init__(self, input_nc=1, output_nc=1, lr=0.0002, beta1=0.5, lambda_cycle=10.0, lambda_identity=5.0):\n",
        "        super(CycleGAN, self).__init__()\n",
        "\n",
        "        self.G_AB = Generator(input_nc, output_nc)\n",
        "        self.G_BA = Generator(output_nc, input_nc)\n",
        "        self.D_A = Discriminator(input_nc)\n",
        "        self.D_B = Discriminator(output_nc)\n",
        "\n",
        "        self.optimizer_G = optim.Adam(\n",
        "            list(self.G_AB.parameters()) + list(self.G_BA.parameters()), lr=lr, betas=(beta1, 0.999)\n",
        "        )\n",
        "        self.optimizer_D_A = optim.Adam(self.D_A.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "        self.optimizer_D_B = optim.Adam(self.D_B.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "\n",
        "        self.criterion_GAN = nn.MSELoss()\n",
        "        self.criterion_cycle = nn.L1Loss()\n",
        "        self.criterion_identity = nn.L1Loss()\n",
        "\n",
        "        self.lambda_cycle = lambda_cycle\n",
        "        self.lambda_identity = lambda_identity\n",
        "\n",
        "    def forward(self, x):\n",
        "        fake_B = self.G_AB(x)\n",
        "        fake_A = self.G_BA(x)\n",
        "        return fake_B, fake_A\n",
        "\n",
        "    def generator_step(self, real_A, real_B):\n",
        "        fake_B = self.G_AB(real_A)\n",
        "        fake_A = self.G_BA(real_B)\n",
        "\n",
        "        loss_GAN_AB = self.criterion_GAN(self.D_B(fake_B), torch.ones_like(self.D_B(fake_B)))\n",
        "        loss_GAN_BA = self.criterion_GAN(self.D_A(fake_A), torch.ones_like(self.D_A(fake_A)))\n",
        "\n",
        "        recov_A = self.G_BA(fake_B)\n",
        "        recov_B = self.G_AB(fake_A)\n",
        "        loss_cycle_A = self.criterion_cycle(recov_A, real_A)\n",
        "        loss_cycle_B = self.criterion_cycle(recov_B, real_B)\n",
        "\n",
        "        loss_id_A = self.criterion_identity(self.G_BA(real_A), real_A)\n",
        "        loss_id_B = self.criterion_identity(self.G_AB(real_B), real_B)\n",
        "\n",
        "        loss_G = (\n",
        "            loss_GAN_AB + loss_GAN_BA +\n",
        "            self.lambda_cycle * (loss_cycle_A + loss_cycle_B) +\n",
        "            self.lambda_identity * (loss_id_A + loss_id_B)\n",
        "        )\n",
        "        return loss_G\n",
        "\n",
        "    def discriminator_step(self, real_A, real_B):\n",
        "        fake_A = self.G_BA(real_B).detach()\n",
        "        fake_B = self.G_AB(real_A).detach()\n",
        "\n",
        "        loss_D_A_real = self.criterion_GAN(self.D_A(real_A), torch.ones_like(self.D_A(real_A)))\n",
        "        loss_D_A_fake = self.criterion_GAN(self.D_A(fake_A), torch.zeros_like(self.D_A(fake_A)))\n",
        "        loss_D_A = (loss_D_A_real + loss_D_A_fake) * 0.5\n",
        "\n",
        "        loss_D_B_real = self.criterion_GAN(self.D_B(real_B), torch.ones_like(self.D_B(real_B)))\n",
        "        loss_D_B_fake = self.criterion_GAN(self.D_B(fake_B), torch.zeros_like(self.D_B(fake_B)))\n",
        "        loss_D_B = (loss_D_B_real + loss_D_B_fake) * 0.5\n",
        "\n",
        "        return loss_D_A + loss_D_B\n",
        "\n",
        "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
        "        real_A, real_B = batch\n",
        "\n",
        "        if optimizer_idx == 0:\n",
        "            loss_G = self.generator_step(real_A, real_B)\n",
        "            self.log('loss_G', loss_G, on_step=True, on_epoch=True)\n",
        "            return loss_G\n",
        "\n",
        "        if optimizer_idx == 1:\n",
        "            loss_D = self.discriminator_step(real_A, real_B)\n",
        "            self.log('loss_D', loss_D, on_step=True, on_epoch=True)\n",
        "            return loss_D\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        real_A, real_B = batch\n",
        "        loss_G = self.generator_step(real_A, real_B)\n",
        "        self.log('val_loss_G', loss_G)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        real_A, real_B = batch\n",
        "        fake_B = self.G_AB(real_A)\n",
        "        fake_A = self.G_BA(real_B)\n",
        "\n",
        "        save_image((fake_B + 1) / 2, f\"test_results/fake_B_{batch_idx}.png\")\n",
        "        save_image((fake_A + 1) / 2, f\"test_results/fake_A_{batch_idx}.png\")\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return (\n",
        "            [self.optimizer_G],\n",
        "            [self.optimizer_D_A, self.optimizer_D_B]\n",
        "        )\n",
        "\n",
        "\n",
        "# Data loading\n",
        "def get_dataloaders(batch_size=1):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,)),\n",
        "    ])\n",
        "\n",
        "    dataset_A = datasets.ImageFolder(\"data/domain_A\", transform=transform)\n",
        "    dataset_B = datasets.ImageFolder(\"data/domain_B\", transform=transform)\n",
        "\n",
        "    loader_A = DataLoader(dataset_A, batch_size=batch_size, shuffle=True)\n",
        "    loader_B = DataLoader(dataset_B, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    return loader_A, loader_B\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    loader_A, loader_B = get_dataloaders()\n",
        "\n",
        "    model = CycleGAN(input_nc=1, output_nc=1)\n",
        "\n",
        "    trainer = pl.Trainer(\n",
        "        max_epochs=100,\n",
        "        gpus=1 if torch.cuda.is_available() else 0,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    trainer.fit(model, train_dataloaders=loader_A, val_dataloaders=loader_B)\n",
        "    trainer.test(model, dataloaders=loader_B)\n"
      ],
      "metadata": {
        "id": "y5oUcWZgM5KB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-6CvjibMr6E"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import transforms\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "class UnpairedImageDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Custom Dataset for loading unpaired images from two domains.\n",
        "    \"\"\"\n",
        "    def __init__(self, root_dir_A, root_dir_B, transform=None):\n",
        "        super(UnpairedImageDataset, self).__init__()\n",
        "        self.transform = transform\n",
        "\n",
        "        self.files_A = sorted(os.listdir(root_dir_A))\n",
        "        self.files_B = sorted(os.listdir(root_dir_B))\n",
        "\n",
        "        self.root_dir_A = root_dir_A\n",
        "        self.root_dir_B = root_dir_B\n",
        "\n",
        "    def __len__(self):\n",
        "        return max(len(self.files_A), len(self.files_B))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Load an image from domain A\n",
        "        file_A = self.files_A[idx % len(self.files_A)]\n",
        "        path_A = os.path.join(self.root_dir_A, file_A)\n",
        "        image_A = Image.open(path_A).convert(\"L\")  # Single-channel grayscale\n",
        "\n",
        "        # Load an image from domain B\n",
        "        file_B = self.files_B[idx % len(self.files_B)]\n",
        "        path_B = os.path.join(self.root_dir_B, file_B)\n",
        "        image_B = Image.open(path_B).convert(\"L\")  # Single-channel grayscale\n",
        "\n",
        "        if self.transform:\n",
        "            image_A = self.transform(image_A)\n",
        "            image_B = self.transform(image_B)\n",
        "\n",
        "        return image_A, image_B\n",
        "\n",
        "\n",
        "def get_dataloaders(root_dir_A, root_dir_B, batch_size=1, val_split=0.2):\n",
        "    \"\"\"\n",
        "    Prepares training and validation DataLoaders for unpaired image datasets.\n",
        "\n",
        "    Args:\n",
        "        root_dir_A: Path to images in domain A.\n",
        "        root_dir_B: Path to images in domain B.\n",
        "        batch_size: Batch size for DataLoader.\n",
        "        val_split: Fraction of the dataset to use for validation.\n",
        "\n",
        "    Returns:\n",
        "        train_loader, val_loader\n",
        "    \"\"\"\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,)),  # Normalize to [-1, 1]\n",
        "    ])\n",
        "\n",
        "    dataset = UnpairedImageDataset(root_dir_A, root_dir_B, transform=transform)\n",
        "\n",
        "    val_size = int(len(dataset) * val_split)\n",
        "    train_size = len(dataset) - val_size\n",
        "\n",
        "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return train_loader, val_loader\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Define paths to datasets\n",
        "    root_dir_A = \"data/domain_A\"  # Path to images from domain A\n",
        "    root_dir_B = \"data/domain_B\"  # Path to images from domain B\n",
        "\n",
        "    # Create DataLoaders\n",
        "    train_loader, val_loader = get_dataloaders(root_dir_A, root_dir_B, batch_size=4, val_split=0.2)\n",
        "\n",
        "    # Instantiate the model\n",
        "    model = CycleGAN(input_nc=1, output_nc=1)\n",
        "\n",
        "    # Configure PyTorch Lightning Trainer\n",
        "    trainer = pl.Trainer(\n",
        "        max_epochs=100,\n",
        "        gpus=1 if torch.cuda.is_available() else 0,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n"
      ],
      "metadata": {
        "id": "7lk50Rc_MumR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oegH25U0MxfO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}